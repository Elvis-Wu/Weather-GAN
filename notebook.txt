1. Conv2D(二維卷積層) : 
    CNN中的卷積層，處理二維圖像或具有空間結構的數據。
    卷積操作透過滑動一個可學習的濾波器(卷積核)於input上，提取不同特徵的表示。

2. Dense(全連接層) : 
    也稱為密集連接層，每個神經元與前一層的每個神經元都有連接，因此會接受來自前一層的所有輸入。
    作用是將input的特徵進行線性組合，並透過激活函數(ReLU)生成輸出。通常在NN的最後幾層用於分類或回歸任務

3. Flatten(平鋪層) :
    將多維數據轉為一維向量。

4. ReShape(重塑) : 
    可將圖片重塑為指定大小的形狀

5. Sequential(順序模型) : 
    Keras的容器，用於建構順序神經網路模型，會按照堆疊的順序，創建出NN。
    是一種線性堆疊的模型，每一層都有一個輸入張量和輸出張量。

6. Dropout(隨機失活層) :
    用於減少NN中的過擬和，於訓練期間以一定的概率隨機丟棄神經元的輸出。
    它強制網路在每個訓練步驟中都以不同方式學習，減少對特定神經元的依賴。

7. LeakyReLU :
    一種激活函數

8. tf.GradientTape :
    Tensorflow中用於自動微分(計算梯度)的工具，主要功能是追蹤Tensorflow計算圖中的操作，且可以計算相對於某些張量的梯度。
    a. 計算梯度
    b. 反向傳播(Backpropagation) : 計算相對於某些損失函數的張量的梯度。對訓練非常有用，因為訓練期間要不斷更新模型參數，使損失函數最小化。
    c. 自定義梯度計算
    d. 計算高階梯度

9. fit : 
    深度學習模型訓練的主要入口，用於實際炫練模型，將模型和訓練數據互相匹配，以便模型可以學習適應任務。
    將模型、訓練數據、損失函數和優化器等傳遞給fit，並設置參數 ex:epoch(訓練週期次數), batch_size(批次大小)。fit會自動執行訓練，包括前向傳播、反向傳播、梯度下降等。

10. Callback(回調函數) :
    於模型訓練中執行特定操作或監控訓練進度。